{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, i i will attempt to find the bug that is preventing certain protein mutations from running quickly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simtk.openmm as openmm\n",
    "from openmmtools.constants import kB\n",
    "import simtk.unit as unit\n",
    "temperature = 300 * unit.kelvin\n",
    "kT = kB * temperature\n",
    "beta = 1.0/kT\n",
    "from perses.rjmc.topology_proposal import TopologyProposal, NetworkXMolecule\n",
    "from openmmtools.states import ThermodynamicState, SamplerState, CompoundThermodynamicState\n",
    "from openmmtools import mcmc, utils\n",
    "import openmmtools.cache as cache\n",
    "from perses.dispersed.utils import configure_platform\n",
    "#cache.global_context_cache.platform = configure_platform(utils.get_fastest_platform().getName())\n",
    "from perses.annihilation.lambda_protocol import LambdaProtocol\n",
    "from perses.annihilation.lambda_protocol import RelativeAlchemicalState, LambdaProtocol\n",
    "import openmmtools.integrators as integrators\n",
    "# from protein_test_cycle import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "print(cache.global_context_cache.platform.getName())\n",
    "#print(cache.global_context_cache.platform.getPropertyDefaultValue('CudaPrecision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as f:\n",
    "        htf = pickle.load(f)\n",
    "    return htf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ALA_THR.vac.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7f956fd45f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfast_htf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ALA_SER.vac.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslow_htf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ALA_THR.vac.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# fast_hss, _ = create_hss(f\"fast_debug.nc\", fast_htf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# slow_hss, _ = create_hss(f\"slow_debug.nc\", slow_htf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6d880b67c949>\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mhtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ALA_THR.vac.pkl'"
     ]
    }
   ],
   "source": [
    "fast_htf = deserialize('ALA_SER.vac.pkl')\n",
    "slow_htf = deserialize('ALA_THR.vac.pkl') \n",
    "# fast_hss, _ = create_hss(f\"fast_debug.nc\", fast_htf)\n",
    "# slow_hss, _ = create_hss(f\"slow_debug.nc\", slow_htf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_integrator(htf, constraint_tol):\n",
    "    \"\"\"\n",
    "    create lambda alchemical states, thermodynamic states, sampler states, integrator, and return context, thermostate, sampler_state, integrator\n",
    "    \"\"\"\n",
    "    fast_lambda_alchemical_state = RelativeAlchemicalState.from_system(htf.hybrid_system)\n",
    "    fast_lambda_alchemical_state.set_alchemical_parameters(0.0, LambdaProtocol(functions = 'default'))\n",
    "    \n",
    "    fast_thermodynamic_state = CompoundThermodynamicState(ThermodynamicState(htf.hybrid_system, temperature = temperature),composable_states = [fast_lambda_alchemical_state])\n",
    "    \n",
    "    fast_sampler_state = SamplerState(positions = htf._hybrid_positions, box_vectors = htf.hybrid_system.getDefaultPeriodicBoxVectors())\n",
    "    \n",
    "    integrator_1 = integrators.LangevinIntegrator(temperature = temperature,\n",
    "                                                     timestep = 4.0* unit.femtoseconds,\n",
    "                                                     splitting = 'V R O R V',\n",
    "                                                     measure_shadow_work = False,\n",
    "                                                     measure_heat = False,\n",
    "                                                     constraint_tolerance = constraint_tol,\n",
    "                                                     collision_rate = 5.0 / unit.picoseconds)\n",
    "    \n",
    "    fast_context, fast_integrator = cache.global_context_cache.get_context(fast_thermodynamic_state, integrator_1)\n",
    "    \n",
    "    \n",
    "    fast_sampler_state.apply_to_context(fast_context)\n",
    "    \n",
    "    return fast_context, fast_thermodynamic_state, fast_sampler_state, fast_integrator\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, fast_int = create_integrator(fast_htf, 1e-6)\n",
    "_, _, _, slow_int = create_integrator(slow_htf, 1e-6)\n",
    "_, _, _, slow_int_mod1 = create_integrator(copy.deepcopy(slow_htf), 1e-5)\n",
    "_, _, _, slow_int_mod2 = create_integrator(copy.deepcopy(slow_htf), 1e-4)\n",
    "_, _, _, slow_int_mod3 = create_integrator(copy.deepcopy(slow_htf), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_integrator(integrator, num_steps = 10):\n",
    "    import time\n",
    "    _time = []\n",
    "    integrator.step(1)\n",
    "    for i in range(num_steps):\n",
    "        start = time.time()\n",
    "        integrator.step(1)\n",
    "        end = time.time() - start\n",
    "        _time.append(end)\n",
    "    return np.array(_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = time_integrator(fast_int, num_steps = 100)\n",
    "slow = time_integrator(slow_int, num_steps = 100)\n",
    "slow_mod1 = time_integrator(slow_int_mod1, num_steps = 100)\n",
    "slow_mod2 = time_integrator(slow_int_mod2, num_steps = 100)\n",
    "slow_mod3 = time_integrator(slow_int_mod3, num_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012963438034057618 0.00017365259597791006\n",
      "0.0012608838081359863 0.0001394109475754756\n",
      "0.0012266659736633301 0.00011619802694094898\n",
      "0.001241781711578369 0.00011578275430538863\n",
      "0.0012153458595275878 0.00011124351557612184\n"
     ]
    }
   ],
   "source": [
    "print(np.average(fast), np.std(fast))\n",
    "print(np.average(slow), np.std(slow))\n",
    "print(np.average(slow_mod1), np.std(slow_mod1))\n",
    "print(np.average(slow_mod2), np.std(slow_mod2))\n",
    "print(np.average(slow_mod3), np.std(slow_mod3))\n",
    "#print(np.average(slow_mod), np.std(slow_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^^^^^ perhaps if we remove the constraints, it will run faster? and lo, it does\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now, we have to figure out how we can fix this issue; let's up the constraint tolerance iteratively...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'll iterate over a few orders of magnitude with the constraint tolerance to try to pull up the speed of integration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tol in [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    _, _, _, slow_int = create_integrator(fast_htf, tol)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
