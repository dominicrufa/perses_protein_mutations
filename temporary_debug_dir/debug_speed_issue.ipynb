{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, i i will attempt to find the bug that is preventing certain protein mutations from running quickly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conducting subsequent work with the following platform: CUDA\n",
      "conducting subsequent work with the following platform: CUDA\n",
      "conducting subsequent work with the following platform: CUDA\n"
     ]
    }
   ],
   "source": [
    "import simtk.openmm as openmm\n",
    "from openmmtools.constants import kB\n",
    "import simtk.unit as unit\n",
    "temperature = 300 * unit.kelvin\n",
    "kT = kB * temperature\n",
    "beta = 1.0/kT\n",
    "from perses.rjmc.topology_proposal import TopologyProposal, NetworkXMolecule\n",
    "from openmmtools.states import ThermodynamicState, SamplerState, CompoundThermodynamicState\n",
    "from openmmtools import mcmc, utils\n",
    "import openmmtools.cache as cache\n",
    "from perses.dispersed.utils import configure_platform\n",
    "#cache.global_context_cache.platform = configure_platform(utils.get_fastest_platform().getName())\n",
    "from perses.annihilation.lambda_protocol import LambdaProtocol\n",
    "from perses.annihilation.lambda_protocol import RelativeAlchemicalState, LambdaProtocol\n",
    "import openmmtools.integrators as integrators\n",
    "from protein_test_cycle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we should be using CUDA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n",
      "mixed\n"
     ]
    }
   ],
   "source": [
    "print(cache.global_context_cache.platform.getName())\n",
    "print(cache.global_context_cache.platform.getPropertyDefaultValue('CudaPrecision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm fast*.nc\")\n",
    "os.system(f\"rm slow*.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hss(reporter_name, hybrid_factory, selection_string ='all', checkpoint_interval = 1, n_states = 13):\n",
    "    lambda_protocol = LambdaProtocol(functions='default')\n",
    "    reporter = MultiStateReporter(reporter_name, analysis_particle_indices = hybrid_factory.hybrid_topology.select(selection_string), checkpoint_interval = checkpoint_interval)\n",
    "    hss = HybridRepexSampler(mcmc_moves=mcmc.LangevinSplittingDynamicsMove(timestep= 4.0 * unit.femtoseconds,\n",
    "                                                                                 collision_rate=5.0 / unit.picosecond,\n",
    "                                                                                 n_steps=1,\n",
    "                                                                                 reassign_velocities=False,\n",
    "                                                                                 n_restart_attempts=20,\n",
    "                                                                                 splitting=\"V R R R O R R R V\",\n",
    "                                                                                 constraint_tolerance=1e-06),\n",
    "                                                                                 hybrid_factory=hybrid_factory, online_analysis_interval=10)\n",
    "    hss.setup(n_states=n_states, temperature=300*unit.kelvin,storage_file=reporter,lambda_protocol=lambda_protocol,endstates=False)\n",
    "    return hss, reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as f:\n",
    "        htf = pickle.load(f)\n",
    "    return htf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_htf = deserialize('ALA_SER.vac.pkl')\n",
    "slow_htf = deserialize('ALA_THR.vac.pkl') \n",
    "# fast_hss, _ = create_hss(f\"fast_debug.nc\", fast_htf)\n",
    "# slow_hss, _ = create_hss(f\"slow_debug.nc\", slow_htf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_hss.extend(2)\n",
    "print(f\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "slow_hss.extend(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see above, even in vacuum, there is a big difference in the replica propagation time between the fast and slow systems, even in vacuum;\n",
    "perhaps if we remove the constraints in the slow system, we can fix the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_htf_mod = copy.deepcopy(slow_htf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_old_atoms': {11, 12, 13},\n",
       " 'unique_new_atoms': {22, 23, 24, 25, 26, 27, 28},\n",
       " 'core_atoms': {4, 6, 7, 8, 9, 10, 14, 15, 16},\n",
       " 'environment_atoms': {0, 1, 2, 3, 5, 17, 18, 19, 20, 21}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_htf._atom_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_constraints = slow_htf_mod._hybrid_system.getNumConstraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_pdb(topology, positions, output_pdb = 'test_new.pdb'):\n",
    "    \"\"\"\n",
    "    create a pdb of the geometry proposal (only new system)\n",
    "    \"\"\"\n",
    "    import mdtraj as md\n",
    "    _positions =  np.array(positions.value_in_unit(unit.nanometer))\n",
    "    print(_positions)\n",
    "    traj = md.Trajectory(_positions, md.Topology.from_openmm(topology))\n",
    "    traj.save(output_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<simtk.openmm.openmm.CustomBondForce; proxy of <Swig Object of type 'OpenMM::CustomBondForce *' at 0x2acb936a5db0> >,\n",
       " <simtk.openmm.openmm.HarmonicBondForce; proxy of <Swig Object of type 'OpenMM::HarmonicBondForce *' at 0x2acb936a56c0> >,\n",
       " <simtk.openmm.openmm.CustomAngleForce; proxy of <Swig Object of type 'OpenMM::CustomAngleForce *' at 0x2acb936a5d80> >,\n",
       " <simtk.openmm.openmm.HarmonicAngleForce; proxy of <Swig Object of type 'OpenMM::HarmonicAngleForce *' at 0x2acb936a5f00> >,\n",
       " <simtk.openmm.openmm.CustomTorsionForce; proxy of <Swig Object of type 'OpenMM::CustomTorsionForce *' at 0x2acb936a5ea0> >,\n",
       " <simtk.openmm.openmm.PeriodicTorsionForce; proxy of <Swig Object of type 'OpenMM::PeriodicTorsionForce *' at 0x2acb936a5ed0> >,\n",
       " <simtk.openmm.openmm.NonbondedForce; proxy of <Swig Object of type 'OpenMM::NonbondedForce *' at 0x2acb936a5c30> >,\n",
       " <simtk.openmm.openmm.CustomNonbondedForce; proxy of <Swig Object of type 'OpenMM::CustomNonbondedForce *' at 0x2acb936a5cf0> >,\n",
       " <simtk.openmm.openmm.CustomBondForce; proxy of <Swig Object of type 'OpenMM::CustomBondForce *' at 0x2acb936a5f60> >]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_htf_mod._hybrid_system.getForces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bonds = slow_htf._hybrid_system.getForce(0).getNumBonds()\n",
    "for i in range(num_bonds):\n",
    "    print(slow_htf._hybrid_system.getForce(0).getBondParameters(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bonds = slow_htf._hybrid_system.getForce(1).getNumBonds()\n",
    "for i in range(num_bonds):\n",
    "    print(slow_htf._hybrid_system.getForce(1).getBondParameters(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_htf_mod._hybrid_topology\n",
    "table, bonds = md.Topology.from_openmm(slow_htf_mod._topology_proposal._old_topology).to_dataframe()\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_constraints):\n",
    "    params = slow_htf_mod._hybrid_system.getConstraintParameters(i)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(num_constraints)):\n",
    "    slow_htf_mod._hybrid_system.removeConstraint(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_hss_mod, _ = create_hss(f\"slow_mod_debug.nc\", slow_htf_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_hss_mod.extend(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_integrator(htf, constraint_tol):\n",
    "    \"\"\"\n",
    "    create lambda alchemical states, thermodynamic states, sampler states, integrator, and return context, thermostate, sampler_state, integrator\n",
    "    \"\"\"\n",
    "    fast_lambda_alchemical_state = RelativeAlchemicalState.from_system(htf.hybrid_system)\n",
    "    fast_lambda_alchemical_state.set_alchemical_parameters(0.0, LambdaProtocol(functions = 'default'))\n",
    "    \n",
    "    fast_thermodynamic_state = CompoundThermodynamicState(ThermodynamicState(htf.hybrid_system, temperature = temperature),composable_states = [fast_lambda_alchemical_state])\n",
    "    \n",
    "    fast_sampler_state = SamplerState(positions = htf._hybrid_positions, box_vectors = htf.hybrid_system.getDefaultPeriodicBoxVectors())\n",
    "    \n",
    "    integrator_1 = integrators.LangevinIntegrator(temperature = temperature,\n",
    "                                                     timestep = 4.0* unit.femtoseconds,\n",
    "                                                     splitting = 'V R O R V',\n",
    "                                                     measure_shadow_work = False,\n",
    "                                                     measure_heat = False,\n",
    "                                                     constraint_tolerance = constraint_tol,\n",
    "                                                     collision_rate = 5.0 / unit.picoseconds)\n",
    "    \n",
    "    fast_context, fast_integrator = cache.global_context_cache.get_context(fast_thermodynamic_state, integrator_1)\n",
    "    \n",
    "    \n",
    "    fast_sampler_state.apply_to_context(fast_context)\n",
    "    \n",
    "    return fast_context, fast_thermodynamic_state, fast_sampler_state, fast_integrator\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, fast_int = create_integrator(fast_htf, 1e-6)\n",
    "_, _, _, slow_int = create_integrator(slow_htf, 1e-6)\n",
    "_, _, _, slow_int_mod1 = create_integrator(copy.deepcopy(slow_htf), 1e-5)\n",
    "_, _, _, slow_int_mod2 = create_integrator(copy.deepcopy(slow_htf), 1e-4)\n",
    "_, _, _, slow_int_mod3 = create_integrator(copy.deepcopy(slow_htf), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_integrator(integrator, num_steps = 10):\n",
    "    import time\n",
    "    _time = []\n",
    "    integrator.step(1)\n",
    "    for i in range(num_steps):\n",
    "        start = time.time()\n",
    "        integrator.step(1)\n",
    "        end = time.time() - start\n",
    "        _time.append(end)\n",
    "    return np.array(_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = time_integrator(fast_int, num_steps = 100)\n",
    "slow = time_integrator(slow_int, num_steps = 100)\n",
    "slow_mod1 = time_integrator(slow_int_mod1, num_steps = 100)\n",
    "slow_mod2 = time_integrator(slow_int_mod2, num_steps = 100)\n",
    "slow_mod3 = time_integrator(slow_int_mod3, num_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016542673110961915 8.413250400535065e-05\n",
      "0.0010826468467712402 8.570893828375499e-05\n",
      "0.001002357006072998 4.801813747161436e-05\n",
      "0.0010527682304382324 0.00024120706113980742\n",
      "0.0009982705116271973 5.470035517064183e-05\n"
     ]
    }
   ],
   "source": [
    "print(np.average(fast), np.std(fast))\n",
    "print(np.average(slow), np.std(slow))\n",
    "print(np.average(slow_mod1), np.std(slow_mod1))\n",
    "print(np.average(slow_mod2), np.std(slow_mod2))\n",
    "print(np.average(slow_mod3), np.std(slow_mod3))\n",
    "#print(np.average(slow_mod), np.std(slow_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^^^^^ perhaps if we remove the constraints, it will run faster? and lo, it does\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now, we have to figure out how we can fix this issue; let's up the constraint tolerance iteratively...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'll iterate over a few orders of magnitude with the constraint tolerance to try to pull up the speed of integration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tol in [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    _, _, _, slow_int = create_integrator(fast_htf, tol)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
